{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a797b411-ba32-4a49-8254-fd3b57caf76c",
   "metadata": {},
   "source": [
    "## Importing libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd2df09-6a25-4686-b1ff-392d729c4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc02188-33e9-4af6-877e-7b343c69de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add one level up directory to the path\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Import custom modules\n",
    "from src.data import *\n",
    "from src.machine_translation import *\n",
    "from src.data.utils import get_dataset\n",
    "from src.data.preprocess import clean_text\n",
    "from src.data.tokenizer import CustomBartTokenizer\n",
    "from src.machine_translation.translate import translate\n",
    "from src.machine_translation.net import CodeMixedModel, CodeMixedModelHGTrainer\n",
    "from src.machine_translation.models.bart_conditional import BartForConditionalGeneration\n",
    "from src.machine_translation.utils import get_tokenized_dataset_models, get_data_loader_models, calculate_sacrebleu_score, calculate_chrf_score, calculate_bert_score, calculate_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb9724-cdf5-458c-9ba9-854da0b39806",
   "metadata": {},
   "source": [
    "## Data acquisition, cleaning and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22ec356-0bbb-4f7b-8aa7-b7d5d7ba8879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 193 ms, sys: 18.8 ms, total: 212 ms\n",
      "Wall time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df, validation_df, test_df = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e76ede-e303-4558-8f66-810de6ef9330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi_en</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film ka kya naam hai</td>\n",
       "      <td>What's the name of the movie</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>namaste, sada hua tomatoes score mahaan hai, l...</td>\n",
       "      <td>Hi, the rotten tomatoes score is great but the...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kya aapako lagata hai ki aapako film pasand aa...</td>\n",
       "      <td>Do you think you will like the movie</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yah kis tarah kee philm hai</td>\n",
       "      <td>What kind of movie is it</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>film  kab banee thee?</td>\n",
       "      <td>when was the movie made?</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174438</th>\n",
       "      <td>Thik hai\\n</td>\n",
       "      <td>Ok.</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174439</th>\n",
       "      <td>Thik hai bhai\\n</td>\n",
       "      <td>ok bro</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174440</th>\n",
       "      <td>Kya ham chalu kar sakte hai?\\n</td>\n",
       "      <td>shall we continue?</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174441</th>\n",
       "      <td>Kya aapko pasand hai hamare saath\\n</td>\n",
       "      <td>do you like we can</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174442</th>\n",
       "      <td>Haa mere pass pandrah thanks hai\\n</td>\n",
       "      <td>Yeah I have fifteen thanks.</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    hi_en  \\\n",
       "0                                    film ka kya naam hai   \n",
       "1       namaste, sada hua tomatoes score mahaan hai, l...   \n",
       "2       kya aapako lagata hai ki aapako film pasand aa...   \n",
       "3                             yah kis tarah kee philm hai   \n",
       "4                                   film  kab banee thee?   \n",
       "...                                                   ...   \n",
       "174438                                         Thik hai\\n   \n",
       "174439                                    Thik hai bhai\\n   \n",
       "174440                     Kya ham chalu kar sakte hai?\\n   \n",
       "174441                Kya aapko pasand hai hamare saath\\n   \n",
       "174442                 Haa mere pass pandrah thanks hai\\n   \n",
       "\n",
       "                                                       en            source  \n",
       "0                            What's the name of the movie  cmu_hinglish_dog  \n",
       "1       Hi, the rotten tomatoes score is great but the...  cmu_hinglish_dog  \n",
       "2                    Do you think you will like the movie  cmu_hinglish_dog  \n",
       "3                                What kind of movie is it  cmu_hinglish_dog  \n",
       "4                                when was the movie made?  cmu_hinglish_dog  \n",
       "...                                                   ...               ...  \n",
       "174438                                                Ok.              linc  \n",
       "174439                                             ok bro              linc  \n",
       "174440                                 shall we continue?              linc  \n",
       "174441                                 do you like we can              linc  \n",
       "174442                        Yeah I have fifteen thanks.              linc  \n",
       "\n",
       "[174443 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4136fec-19ad-4643-83c6-3301a0388e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi_en</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie kis baare me hai?</td>\n",
       "      <td>What is the movie about?</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie ek chhote bacche Kevin k baare me hai ji...</td>\n",
       "      <td>the movie is about a young child named Kevin w...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kya wo jaan bhuj k abandon karte hai?</td>\n",
       "      <td>Did they abandon him on purpose?</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nahi, wo uska track lose kardete hai kyuki bah...</td>\n",
       "      <td>no they had lost track of him since they had m...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kya wo realize karte hai k wo chhut gaya aur u...</td>\n",
       "      <td>Did they realize they lost track of him and co...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>Sunkar good movie hai. Kya ham finish kar skat...</td>\n",
       "      <td>Sounds like a good movie. Can we finish now?</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>Yep. Thanks baat karne ke liye\\n</td>\n",
       "      <td>Yep. Thanks for chatting</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>Thanks, mei dekhati hui. Achi baat hai\\n</td>\n",
       "      <td>thanks, I will watch it. SOunds good</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>kya tumhe movie Despicable Me pasand hai?\\n</td>\n",
       "      <td>Did you like the movie Despicable Me?</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>mujhe nahi lagta ki ye movie 2010 me aayi thi,...</td>\n",
       "      <td>I did not realize this movie came out in 2010,...</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3243 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hi_en  \\\n",
       "0                               movie kis baare me hai?   \n",
       "1     Movie ek chhote bacche Kevin k baare me hai ji...   \n",
       "2                 Kya wo jaan bhuj k abandon karte hai?   \n",
       "3     nahi, wo uska track lose kardete hai kyuki bah...   \n",
       "4     Kya wo realize karte hai k wo chhut gaya aur u...   \n",
       "...                                                 ...   \n",
       "3238  Sunkar good movie hai. Kya ham finish kar skat...   \n",
       "3239                   Yep. Thanks baat karne ke liye\\n   \n",
       "3240           Thanks, mei dekhati hui. Achi baat hai\\n   \n",
       "3241        kya tumhe movie Despicable Me pasand hai?\\n   \n",
       "3242  mujhe nahi lagta ki ye movie 2010 me aayi thi,...   \n",
       "\n",
       "                                                     en            source  \n",
       "0                              What is the movie about?  cmu_hinglish_dog  \n",
       "1     the movie is about a young child named Kevin w...  cmu_hinglish_dog  \n",
       "2                      Did they abandon him on purpose?  cmu_hinglish_dog  \n",
       "3     no they had lost track of him since they had m...  cmu_hinglish_dog  \n",
       "4     Did they realize they lost track of him and co...  cmu_hinglish_dog  \n",
       "...                                                 ...               ...  \n",
       "3238       Sounds like a good movie. Can we finish now?              linc  \n",
       "3239                           Yep. Thanks for chatting              linc  \n",
       "3240               thanks, I will watch it. SOunds good              linc  \n",
       "3241              Did you like the movie Despicable Me?              linc  \n",
       "3242  I did not realize this movie came out in 2010,...              linc  \n",
       "\n",
       "[3243 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f002715-2359-4b51-b7b9-13e0c2738b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi_en</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oye ledki kitni mazakiya movie dekh rhi ho ?</td>\n",
       "      <td>ah mean girls. such a funny movie. have you se...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ha muje bhi hassi mazak ki movies pasand par y...</td>\n",
       "      <td>Yeah, even though I love comedies, this wasn't...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kese tina ka jhuti writing isme achi the usne ...</td>\n",
       "      <td>how come. thought tina fey's writing was fanta...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muje kahani bhute achi lagi aur unhone ise dac...</td>\n",
       "      <td>I loved the story &amp; how true they made it in h...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab samja muje nhi pta tha ki aap sahi admi hai...</td>\n",
       "      <td>I see. i didn't realize it was 14 years ago. y...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067</th>\n",
       "      <td>alarm ko abhi stop kare</td>\n",
       "      <td>Stop alarm now</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7068</th>\n",
       "      <td>Har ghante ke liye alarm set kare</td>\n",
       "      <td>set alarm every hour</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7069</th>\n",
       "      <td>Bobby ko text kare</td>\n",
       "      <td>text Bobby</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7070</th>\n",
       "      <td>Muje shaam 6 baje laundry ko pick up karne ke ...</td>\n",
       "      <td>remind me to pick up laundry at 6 pm</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>Kya aap muje har subah 6 baje apne baccho ko j...</td>\n",
       "      <td>Can you remind me to wake my kids up every mor...</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7072 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hi_en  \\\n",
       "0          oye ledki kitni mazakiya movie dekh rhi ho ?   \n",
       "1     ha muje bhi hassi mazak ki movies pasand par y...   \n",
       "2     kese tina ka jhuti writing isme achi the usne ...   \n",
       "3     muje kahani bhute achi lagi aur unhone ise dac...   \n",
       "4     ab samja muje nhi pta tha ki aap sahi admi hai...   \n",
       "...                                                 ...   \n",
       "7067                            alarm ko abhi stop kare   \n",
       "7068                  Har ghante ke liye alarm set kare   \n",
       "7069                                 Bobby ko text kare   \n",
       "7070  Muje shaam 6 baje laundry ko pick up karne ke ...   \n",
       "7071  Kya aap muje har subah 6 baje apne baccho ko j...   \n",
       "\n",
       "                                                     en            source  \n",
       "0     ah mean girls. such a funny movie. have you se...  cmu_hinglish_dog  \n",
       "1     Yeah, even though I love comedies, this wasn't...  cmu_hinglish_dog  \n",
       "2     how come. thought tina fey's writing was fanta...  cmu_hinglish_dog  \n",
       "3     I loved the story & how true they made it in h...  cmu_hinglish_dog  \n",
       "4     I see. i didn't realize it was 14 years ago. y...  cmu_hinglish_dog  \n",
       "...                                                 ...               ...  \n",
       "7067                                     Stop alarm now               top  \n",
       "7068                               set alarm every hour               top  \n",
       "7069                                         text Bobby               top  \n",
       "7070               remind me to pick up laundry at 6 pm               top  \n",
       "7071  Can you remind me to wake my kids up every mor...               top  \n",
       "\n",
       "[7072 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e93f1af-c168-4d30-8d38-f08a1245b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 10.4 ms, total: 2.87 s\n",
      "Wall time: 2.87 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi_en</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film ka kya naam hai</td>\n",
       "      <td>what's the name of the movie</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>namaste, sada hua tomatoes score mahaan hai, l...</td>\n",
       "      <td>hi, the rotten tomatoes score is great but the...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kya aapako lagata hai ki aapako film pasand aa...</td>\n",
       "      <td>do you think you will like the movie</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yah kis tarah kee philm hai</td>\n",
       "      <td>what kind of movie is it</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>film kab banee thee?</td>\n",
       "      <td>when was the movie made?</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174438</th>\n",
       "      <td>thik hai</td>\n",
       "      <td>ok.</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174439</th>\n",
       "      <td>thik hai bhai</td>\n",
       "      <td>ok bro</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174440</th>\n",
       "      <td>kya ham chalu kar sakte hai?</td>\n",
       "      <td>shall we continue?</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174441</th>\n",
       "      <td>kya aapko pasand hai hamare saath</td>\n",
       "      <td>do you like we can</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174442</th>\n",
       "      <td>haa mere pass pandrah thanks hai</td>\n",
       "      <td>yeah i have fifteen thanks.</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    hi_en  \\\n",
       "0                                    film ka kya naam hai   \n",
       "1       namaste, sada hua tomatoes score mahaan hai, l...   \n",
       "2       kya aapako lagata hai ki aapako film pasand aa...   \n",
       "3                             yah kis tarah kee philm hai   \n",
       "4                                    film kab banee thee?   \n",
       "...                                                   ...   \n",
       "174438                                           thik hai   \n",
       "174439                                      thik hai bhai   \n",
       "174440                       kya ham chalu kar sakte hai?   \n",
       "174441                  kya aapko pasand hai hamare saath   \n",
       "174442                   haa mere pass pandrah thanks hai   \n",
       "\n",
       "                                                       en            source  \n",
       "0                            what's the name of the movie  cmu_hinglish_dog  \n",
       "1       hi, the rotten tomatoes score is great but the...  cmu_hinglish_dog  \n",
       "2                    do you think you will like the movie  cmu_hinglish_dog  \n",
       "3                                what kind of movie is it  cmu_hinglish_dog  \n",
       "4                                when was the movie made?  cmu_hinglish_dog  \n",
       "...                                                   ...               ...  \n",
       "174438                                                ok.              linc  \n",
       "174439                                             ok bro              linc  \n",
       "174440                                 shall we continue?              linc  \n",
       "174441                                 do you like we can              linc  \n",
       "174442                        yeah i have fifteen thanks.              linc  \n",
       "\n",
       "[174443 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Cleaning train_df\n",
    "train_df = train_df.applymap(clean_text)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1016d417-f744-4caa-9773-e968eafc35c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 ms, sys: 937 µs, total: 54.2 ms\n",
      "Wall time: 53.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi_en</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie kis baare me hai?</td>\n",
       "      <td>what is the movie about?</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie ek chhote bacche kevin k baare me hai ji...</td>\n",
       "      <td>the movie is about a young child named kevin w...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kya wo jaan bhuj k abandon karte hai?</td>\n",
       "      <td>did they abandon him on purpose?</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nahi, wo uska track lose kardete hai kyuki bah...</td>\n",
       "      <td>no they had lost track of him since they had m...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kya wo realize karte hai k wo chhut gaya aur u...</td>\n",
       "      <td>did they realize they lost track of him and co...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>sunkar good movie hai. kya ham finish kar skat...</td>\n",
       "      <td>sounds like a good movie. can we finish now?</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>yep. thanks baat karne ke liye</td>\n",
       "      <td>yep. thanks for chatting</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>thanks, mei dekhati hui. achi baat hai</td>\n",
       "      <td>thanks, i will watch it. sounds good</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>kya tumhe movie despicable me pasand hai?</td>\n",
       "      <td>did you like the movie despicable me?</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>mujhe nahi lagta ki ye movie 2010 me aayi thi,...</td>\n",
       "      <td>i did not realize this movie came out in 2010,...</td>\n",
       "      <td>linc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3243 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hi_en  \\\n",
       "0                               movie kis baare me hai?   \n",
       "1     movie ek chhote bacche kevin k baare me hai ji...   \n",
       "2                 kya wo jaan bhuj k abandon karte hai?   \n",
       "3     nahi, wo uska track lose kardete hai kyuki bah...   \n",
       "4     kya wo realize karte hai k wo chhut gaya aur u...   \n",
       "...                                                 ...   \n",
       "3238  sunkar good movie hai. kya ham finish kar skat...   \n",
       "3239                     yep. thanks baat karne ke liye   \n",
       "3240             thanks, mei dekhati hui. achi baat hai   \n",
       "3241          kya tumhe movie despicable me pasand hai?   \n",
       "3242  mujhe nahi lagta ki ye movie 2010 me aayi thi,...   \n",
       "\n",
       "                                                     en            source  \n",
       "0                              what is the movie about?  cmu_hinglish_dog  \n",
       "1     the movie is about a young child named kevin w...  cmu_hinglish_dog  \n",
       "2                      did they abandon him on purpose?  cmu_hinglish_dog  \n",
       "3     no they had lost track of him since they had m...  cmu_hinglish_dog  \n",
       "4     did they realize they lost track of him and co...  cmu_hinglish_dog  \n",
       "...                                                 ...               ...  \n",
       "3238       sounds like a good movie. can we finish now?              linc  \n",
       "3239                           yep. thanks for chatting              linc  \n",
       "3240               thanks, i will watch it. sounds good              linc  \n",
       "3241              did you like the movie despicable me?              linc  \n",
       "3242  i did not realize this movie came out in 2010,...              linc  \n",
       "\n",
       "[3243 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Cleaning validation_df\n",
    "validation_df = validation_df.applymap(clean_text)\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46573bf4-a9cc-49d5-9659-3966fc9a80b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 ms, sys: 938 µs, total: 108 ms\n",
      "Wall time: 107 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi_en</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oye ledki kitni mazakiya movie dekh rhi ho ?</td>\n",
       "      <td>ah mean girls. such a funny movie. have you se...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ha muje bhi hassi mazak ki movies pasand par y...</td>\n",
       "      <td>yeah, even though i love comedies, this wasn't...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kese tina ka jhuti writing isme achi the usne ...</td>\n",
       "      <td>how come. thought tina fey's writing was fanta...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muje kahani bhute achi lagi aur unhone ise dac...</td>\n",
       "      <td>i loved the story &amp; how true they made it in h...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab samja muje nhi pta tha ki aap sahi admi hai...</td>\n",
       "      <td>i see. i didn't realize it was 14 years ago. y...</td>\n",
       "      <td>cmu_hinglish_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067</th>\n",
       "      <td>alarm ko abhi stop kare</td>\n",
       "      <td>stop alarm now</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7068</th>\n",
       "      <td>har ghante ke liye alarm set kare</td>\n",
       "      <td>set alarm every hour</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7069</th>\n",
       "      <td>bobby ko text kare</td>\n",
       "      <td>text bobby</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7070</th>\n",
       "      <td>muje shaam 6 baje laundry ko pick up karne ke ...</td>\n",
       "      <td>remind me to pick up laundry at 6 pm</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>kya aap muje har subah 6 baje apne baccho ko j...</td>\n",
       "      <td>can you remind me to wake my kids up every mor...</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7072 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hi_en  \\\n",
       "0          oye ledki kitni mazakiya movie dekh rhi ho ?   \n",
       "1     ha muje bhi hassi mazak ki movies pasand par y...   \n",
       "2     kese tina ka jhuti writing isme achi the usne ...   \n",
       "3     muje kahani bhute achi lagi aur unhone ise dac...   \n",
       "4     ab samja muje nhi pta tha ki aap sahi admi hai...   \n",
       "...                                                 ...   \n",
       "7067                            alarm ko abhi stop kare   \n",
       "7068                  har ghante ke liye alarm set kare   \n",
       "7069                                 bobby ko text kare   \n",
       "7070  muje shaam 6 baje laundry ko pick up karne ke ...   \n",
       "7071  kya aap muje har subah 6 baje apne baccho ko j...   \n",
       "\n",
       "                                                     en            source  \n",
       "0     ah mean girls. such a funny movie. have you se...  cmu_hinglish_dog  \n",
       "1     yeah, even though i love comedies, this wasn't...  cmu_hinglish_dog  \n",
       "2     how come. thought tina fey's writing was fanta...  cmu_hinglish_dog  \n",
       "3     i loved the story & how true they made it in h...  cmu_hinglish_dog  \n",
       "4     i see. i didn't realize it was 14 years ago. y...  cmu_hinglish_dog  \n",
       "...                                                 ...               ...  \n",
       "7067                                     stop alarm now               top  \n",
       "7068                               set alarm every hour               top  \n",
       "7069                                         text bobby               top  \n",
       "7070               remind me to pick up laundry at 6 pm               top  \n",
       "7071  can you remind me to wake my kids up every mor...               top  \n",
       "\n",
       "[7072 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Cleaning test_df\n",
    "test_df = test_df.applymap(clean_text)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815fbe5-c088-40b5-9406-2c942a6d09f8",
   "metadata": {},
   "source": [
    "## Data tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c18f562f-3b6a-4424-bb67-f2fadd2fbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 27.5 s, sys: 113 ms, total: 27.7 s\n",
      "Wall time: 48.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bart_tokenizer = CustomBartTokenizer().build()\n",
    "bart_tokenizer_scratch = CustomBartTokenizer().build(data=train_df[\"hi_en\"], tokenizer_style=STYLE.SCRATCH.value)\n",
    "bart_tokenizer_append = CustomBartTokenizer().build(data=train_df[\"hi_en\"], tokenizer_style=STYLE.APPEND.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762a0654-e873-425b-9c82-8929723277e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hello! Ye CSCI 544 ka project he. Ye project Code-Mixed Machine Translation ke bara me he. Hamane hamari khoon bahahe.\"\n",
    "query = clean_text(text=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2270383-2d6c-41ae-a798-5d61fd71ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "This is an example of using the default Bart Tokenizer.\n",
      "\n",
      "Sentence: hello! ye csci 544 ka project he. ye project code-mixed machine translation ke bara me he. hamane hamari khoon bahahe.\n",
      "\n",
      "Tokenized word: ['<s>', 'hello', '!', 'Ġye', 'Ġc', 'sci', 'Ġ5', '44', 'Ġka', 'Ġproject', 'Ġhe', '.', 'Ġye', 'Ġproject', 'Ġcode', '-', 'm', 'ixed', 'Ġmachine', 'Ġtranslation', 'Ġke', 'Ġbar', 'a', 'Ġme', 'Ġhe', '.', 'Ġham', 'ane', 'Ġham', 'ari', 'Ġkh', 'oon', 'Ġb', 'aha', 'he', '.', '</s>']\n",
      "\n",
      "Tokenized idx: [0, 42891, 328, 32440, 740, 43428, 195, 3305, 4661, 695, 37, 4, 32440, 695, 3260, 12, 119, 24194, 3563, 19850, 7321, 2003, 102, 162, 37, 4, 11402, 1728, 11402, 1512, 16447, 3863, 741, 11695, 700, 4, 2]\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "token_idx = bart_tokenizer.encode(query, add_special_tokens=True)\n",
    "token_word = bart_tokenizer.convert_ids_to_tokens(token_idx)\n",
    "print('#'*100)\n",
    "print(\"This is an example of using the default Bart Tokenizer.\\n\")\n",
    "print(f\"Sentence: {query}\\n\")\n",
    "print(f\"Tokenized word: {token_word}\\n\")\n",
    "print(f\"Tokenized idx: {token_idx}\")\n",
    "print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4bfaaba-91ad-467e-ac94-c3b55c4b5de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "This is an example of the Bart Tokenizer that is trained from scratch.\n",
      "\n",
      "Sentence: hello! ye csci 544 ka project he. ye project code-mixed machine translation ke bara me he. hamane hamari khoon bahahe.\n",
      "\n",
      "Tokenized word: ['<s>', 'hello', '!', 'Ġye', 'Ġc', 'sci', 'Ġ5', '44', 'Ġka', 'Ġproject', 'Ġhe', '.', 'Ġye', 'Ġproject', 'Ġcode', '-', 'mix', 'ed', 'Ġmachine', 'Ġtrans', 'lation', 'Ġke', 'Ġbara', 'Ġme', 'Ġhe', '.', 'Ġhamane', 'Ġhamari', 'Ġkhoon', 'Ġbaha', 'he', '.', '</s>']\n",
      "\n",
      "Tokenized idx: [0, 2317, 4, 520, 288, 21554, 466, 11342, 312, 3070, 356, 17, 520, 3070, 6438, 16, 19530, 517, 6262, 3397, 18402, 271, 17190, 284, 356, 17, 11714, 4630, 10623, 13967, 282, 17, 2]\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "token_idx = bart_tokenizer_scratch.encode(query, add_special_tokens=True)\n",
    "token_word = bart_tokenizer_scratch.convert_ids_to_tokens(token_idx)\n",
    "print('#'*100)\n",
    "print(\"This is an example of the Bart Tokenizer that is trained from scratch.\\n\")\n",
    "print(f\"Sentence: {query}\\n\")\n",
    "print(f\"Tokenized word: {token_word}\\n\")\n",
    "print(f\"Tokenized idx: {token_idx}\")\n",
    "print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ad95f1b-8b6a-4bc0-be8c-4a18fa8775f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "This is an example of the Bart Tokenizer to which we append our new data.\n",
      "\n",
      "Sentence: hello! ye csci 544 ka project he. ye project code-mixed machine translation ke bara me he. hamane hamari khoon bahahe.\n",
      "\n",
      "Tokenized word: ['<s>', 'hello', '!', 'Ġ', 'ye', 'Ġ', 'csc', 'i', 'Ġ', '54', '4', 'Ġ', 'ka', 'Ġ', 'project', 'Ġ', 'he', '.', 'Ġ', 'ye', 'Ġ', 'project', 'Ġ', 'code', '-', 'mix', 'ed', 'Ġ', 'mach', 'ine', 'Ġ', 'trans', 'lation', 'Ġ', 'ke', 'Ġ', 'bara', 'Ġ', 'me', 'Ġ', 'he', '.', 'Ġ', 'hamane', 'Ġ', 'hamari', 'Ġ', 'khoo', 'n', 'Ġ', 'baha', 'he', '.', '</s>']\n",
      "\n",
      "Tokenized idx: [0, 42891, 328, 1437, 4717, 1437, 82131, 118, 1437, 4283, 306, 1437, 2348, 1437, 28258, 1437, 700, 4, 1437, 4717, 1437, 28258, 1437, 20414, 12, 39915, 196, 1437, 79389, 833, 1437, 9981, 35019, 1437, 1071, 1437, 31533, 1437, 1794, 1437, 700, 4, 1437, 77062, 1437, 73169, 1437, 64064, 282, 1437, 53028, 700, 4, 2]\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "token_idx = bart_tokenizer_append.encode(query, add_special_tokens=True)\n",
    "token_word = bart_tokenizer_append.convert_ids_to_tokens(token_idx)\n",
    "print('#'*100)\n",
    "print(\"This is an example of the Bart Tokenizer to which we append our new data.\\n\")\n",
    "print(f\"Sentence: {query}\\n\")\n",
    "print(f\"Tokenized word: {token_word}\\n\")\n",
    "print(f\"Tokenized idx: {token_idx}\")\n",
    "print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "390d4005-a4fe-4187-8a41-a987029417b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CPU times: user 13.5 s, sys: 38.8 ms, total: 13.6 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Now that we know how to get a BART-Tokenizer - default, appeded and scratch, let us get the tokenizer for our code-mixed language\n",
    "# and the target language.\n",
    "# Code-Mixed Language - Build a Bart-Tokenizer from scratch.\n",
    "# Target Language (English) - Use the default Bart-Tokenizer.\n",
    "hi_en_bart_tokenizer = CustomBartTokenizer().build(\n",
    "    data=train_df[\"hi_en\"],\n",
    "    tokenizer_style=MBART_TOKENIZER_BPE_BINDING_BART_TOKENIZER_ENCODER_STYLE,\n",
    "    tokenizer_bart_from_pretrained_path=MBART_TOKENIZER_BPE_BINDING_BART_TOKENIZER_ENCODER_FROM_PRETRAINED\n",
    ")\n",
    "en_bart_tokenizer = CustomBartTokenizer().build(\n",
    "    tokenizer_style=MBART_TOKENIZER_BPE_BINDING_BART_TOKENIZER_DECODER_STYLE,\n",
    "    tokenizer_bart_from_pretrained_path=MBART_TOKENIZER_BPE_BINDING_BART_TOKENIZER_DECODER_FROM_PRETRAINED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e43157d2-c90a-4a82-a8fd-f4c9256ca9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinglish tokenizer vocab size: 50265\n",
      "English tokenizer vocab size: 50265\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hinglish tokenizer vocab size: {hi_en_bart_tokenizer.vocab_size}\")\n",
    "print(f\"English tokenizer vocab size: {en_bart_tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79dbbc3c-76c4-4628-a59d-66c142a74489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1764738 hinglish tokens in the train data.\n",
      "There are 1807859 english tokens in the train data.\n",
      "There are 38502 hinglish tokens in the validation data.\n",
      "There are 38366 english tokens in the validation data.\n",
      "There are 70895 hinglish tokens in the test data.\n",
      "There are 69686 english tokens in the test data.\n",
      "CPU times: user 9.23 s, sys: 11.4 ms, total: 9.24 s\n",
      "Wall time: 9.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"There are {train_df['hi_en'].apply(lambda x: calculate_tokens(x, hi_en_bart_tokenizer)).sum()} hinglish tokens in the train data.\")\n",
    "print(f\"There are {train_df['en'].apply(lambda x: calculate_tokens(x, en_bart_tokenizer)).sum()} english tokens in the train data.\")\n",
    "print(f\"There are {validation_df['hi_en'].apply(lambda x: calculate_tokens(x, hi_en_bart_tokenizer)).sum()} hinglish tokens in the validation data.\")\n",
    "print(f\"There are {validation_df['en'].apply(lambda x: calculate_tokens(x, en_bart_tokenizer)).sum()} english tokens in the validation data.\")\n",
    "print(f\"There are {test_df['hi_en'].apply(lambda x: calculate_tokens(x, hi_en_bart_tokenizer)).sum()} hinglish tokens in the test data.\")\n",
    "print(f\"There are {test_df['en'].apply(lambda x: calculate_tokens(x, en_bart_tokenizer)).sum()} english tokens in the test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea448cc8-4d09-40e8-a793-db3b7c6d59d7",
   "metadata": {},
   "source": [
    "## Dataset and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b11bdf5-d384-42da-b618-48310379ffc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'hi_en__en': {'train': <src.machine_translation.data.CodeMixedTokenizedDataset at 0x17f2ae4c0>,\n",
       "              'validation': <src.machine_translation.data.CodeMixedTokenizedDataset at 0x17f2aeee0>,\n",
       "              'test': <src.machine_translation.data.CodeMixedTokenizedDataset at 0x17f2aebe0>}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the tokenized dataset\n",
    "__tokenized_datasets__ = get_tokenized_dataset_models(\n",
    "    train_df=train_df,\n",
    "    validation_df=validation_df,\n",
    "    test_df=test_df,\n",
    "    encoder_tokenizer=hi_en_bart_tokenizer,\n",
    "    decoder_tokenizer=en_bart_tokenizer\n",
    ")\n",
    "__tokenized_datasets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e23c99-b268-450d-a1cd-cd355dca0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "__train_dataset__, __validation_dataset__, __test_dataset__ = __tokenized_datasets__[\"hi_en__en\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "056b96a6-1b55-41aa-a4fd-8cfc44d837be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Dataset\n",
      "Number of instances:  174443\n",
      "Denoising stage:  False\n",
      "Source language:  hi_en\n",
      "Target language:  en\n",
      "Key: input_ids, Value: tensor([    0,  3497,    15, 10386,  1071,  2025,  2185,  6089,   278,    15,\n",
      "         1088,  4175,  2430,  2185,   392, 33673,  1711,  1963,   291,  1104,\n",
      "         1067,  1758,   278,    17,     2,     1,     1,     1,     1,     1]), Value shape: torch.Size([30])\n",
      "Key: attention_mask, Value: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0]), Value shape: torch.Size([30])\n",
      "Key: labels, Value: tensor([    0,  3592,     6,     5, 34485, 18553,  1471,    16,   372,    53,\n",
      "            5, 32820,  7745,  1471,  1302,    10,   410,   614,    10,  1569,\n",
      "            9,    42,  1318,     4,     2,  -100,  -100,  -100,  -100,  -100]), Value shape: torch.Size([30])\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "__train_dataset__.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd21ad39-1fe1-439a-a0e5-424f6084aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data loaders for denoising\n",
    "__data_loaders__ = get_data_loader_models(\n",
    "    train_df=train_df,\n",
    "    validation_df=validation_df,\n",
    "    test_df=test_df,\n",
    "    train_batch_size=8, \n",
    "    validation_batch_size=8, \n",
    "    test_batch_size=8,\n",
    "    encoder_tokenizer=hi_en_bart_tokenizer,\n",
    "    decoder_tokenizer=en_bart_tokenizer, # Get overwritten in the denoising stage\n",
    "    denoising_stage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6245480-16cd-4155-9168-d8abd2af0204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'hi_en__en': {'object': <src.machine_translation.data.CodeMixedDataLoader at 0x2a0ebb5e0>,\n",
       "              'train': <torch.utils.data.dataloader.DataLoader at 0x2a0ebbe80>,\n",
       "              'validation': <torch.utils.data.dataloader.DataLoader at 0x2a0ebba00>,\n",
       "              'test': <torch.utils.data.dataloader.DataLoader at 0x2a0ebb760>}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__data_loaders__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9b1068b-d7ce-45c2-9726-605532100f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "__data_loader__, __train_data_loader__, __validation_data_loader__, __test_data_loader__ = __data_loaders__[\"hi_en__en\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "377b183b-c3e2-4cb2-b3fc-529886fc170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Train Dataloader\n",
      "Batch Size:  8\n",
      "Number of batches:  21806\n",
      "Batch source language shape:  torch.Size([8, 30])\n",
      "Batch source language:  ['kya mere ghar ko koi dusra raasta hai', 'monday aur tuesday ke liye alarms create karo', 'mujhe kitne bajhe nikalna chahiye 5 pm tak new york city pahuchne ke liye', 'alarm abhi mute kare', 'connecticut se rhode island tak kitne miles hai', 'mujhe kal make up karne ke liye yaad dilaye', '5 pm ko dinner lene ke liye reminder set kare', 'kya aj mujhe scarf pehenna chahiye ?']\n",
      "Batch source tokens:  tensor([[    0,   316,   376,   527,   280,   418, 50265,  1557,   278,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   969,   368,   762,   271,   283,   512,   768,   371,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 50265,   551, 50265,  1244,   486,   466,   403,   373,   720,\n",
      "           800,   931,   945,   271,   283,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   857,   555,  4559,   315,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 18173,   291,  9179,  2322,   373,   551,   984, 50265,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 50265,   504,  2364, 50265,   382,   271,   283,   393,   482,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,    24,   403,   280,   904,   929,   271,   283,   347,   334,\n",
      "           315,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 50265, 50265,   377,  7266,  4006,   486,   318,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Batch source attention mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])\n",
      "Batch target language shape:  torch.Size([8, 30])\n",
      "Batch target language:  ['kya mere ghar ko koi dusra raasta hai', 'monday aur tuesday ke liye alarms create karo', 'mujhe kitne bajhe nikalna chahiye 5 pm tak new york city pahuchne ke liye', 'alarm abhi mute kare', 'connecticut se rhode island tak kitne miles hai', 'mujhe kal make up karne ke liye yaad dilaye', '5 pm ko dinner lene ke liye reminder set kare', 'kya aj mujhe scarf pehenna chahiye ?']\n",
      "Batch target tokens:  tensor([[    0,   316,   376,   527,   280,   418,  2518,  1557,   278,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   969,   368,   762,   271,   283,   512,   768,   371,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   348,   551,   543,  1244,   486,   466,   403,   373,   720,\n",
      "           800,   931,   945,   271,   283,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   857,   555,  4559,   315,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 18173,   291,  9179,  2322,   373,   551,   984,   278,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   348,   504,  2364,   522,   382,   271,   283,   393,   482,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,    24,   403,   280,   904,   929,   271,   283,   347,   334,\n",
      "           315,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   316,   687,   377,  7266,  4006,   486,   318,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Batch target attention mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])\n",
      "Batch denoising source language shape:  torch.Size([8, 30])\n",
      "Batch denoising source tokens:  tensor([[    0,   316,   376,   527,   280,   418, 50265,  1557,   278,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   969,   368,   762,   271,   283,   512,   768,   371,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 50265,   551, 50265,  1244,   486,   466,   403,   373,   720,\n",
      "           800,   931,   945,   271,   283,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   857,   555,  4559,   315,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 18173,   291,  9179,  2322,   373,   551,   984, 50265,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 50265,   504,  2364, 50265,   382,   271,   283,   393,   482,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,    24,   403,   280,   904,   929,   271,   283,   347,   334,\n",
      "           315,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 50265, 50265,   377,  7266,  4006,   486,   318,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Batch denoising source decoded:  ['<s>kya mere ghar ko koi<mask> raasta hai</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<s>monday aur tuesday ke liye alarms create karo</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<s><mask> kitne<mask> nikalna chahiye 5 pm tak new york city pahuchne ke liye</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<s>alarm abhi mute kare</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<s>connecticut se rhode island tak kitne miles<mask></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<s><mask> kal make<mask> karne ke liye yaad dilaye</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<s>5 pm ko dinner lene ke liye reminder set kare</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', '<s><mask><mask> mujhe scarf pehenna chahiye?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']\n",
      "Batch denoising labels:  tensor([[    0,   316,   376,   527,   280,   418,  2518,  1557,   278,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   969,   368,   762,   271,   283,   512,   768,   371,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   348,   551,   543,  1244,   486,   466,   403,   373,   720,\n",
      "           800,   931,   945,   271,   283,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   857,   555,  4559,   315,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 18173,   291,  9179,  2322,   373,   551,   984,   278,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   348,   504,  2364,   522,   382,   271,   283,   393,   482,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,    24,   403,   280,   904,   929,   271,   283,   347,   334,\n",
      "           315,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,   316,   687,   377,  7266,  4006,   486,   318,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Batch denoising mask labels:  tensor([[-100, -100, -100, -100, -100, -100, 2518, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100],\n",
      "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100],\n",
      "        [-100,  348, -100,  543, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100],\n",
      "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100],\n",
      "        [-100, -100, -100, -100, -100, -100, -100, -100,  278, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100],\n",
      "        [-100,  348, -100, -100,  522, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100],\n",
      "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100],\n",
      "        [-100,  316,  687, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100]])\n",
      "Batch denoising mask:  tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])\n",
      "Validating train laoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 21806/21806 [00:43<00:00, 505.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation of train loader successful.\n",
      "####################################################################################################\n",
      "Val Dataloader\n",
      "Batch Size:  8\n",
      "Number of batches:  406\n",
      "Validating validation laoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 406/406 [00:33<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation of validation loader successful.\n",
      "####################################################################################################\n",
      "Test Dataloader\n",
      "Batch Size:  8\n",
      "Number of batches:  884\n",
      "Validating test laoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 884/884 [00:33<00:00, 26.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation of test loader successful.\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "__data_loader__.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db184e-1ca9-4700-add3-76765d6c69b5",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98d028b1-0090-487b-8f83-a757a6a7e2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__model__ = BartForConditionalGeneration()\n",
    "__model__.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd3b7372-e905-45ef-a70a-6dfbea178dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has a total of 406291456 number of parameters\n",
      "Model encoder input size:  torch.Size([8, 23])\n",
      "Model decoder input size:  torch.Size([8, 13])\n",
      "Model output type:  <class 'transformers.modeling_outputs.Seq2SeqLMOutput'>\n",
      "Model output size:  torch.Size([8, 13, 50265])\n",
      "Model output:\n",
      " tensor([[[ 1.3886e+01, -1.2782e+00,  5.2260e+00,  ...,  2.7985e-02,\n",
      "          -4.2849e-01,  3.5954e+00],\n",
      "         [-1.4220e+01, -2.2313e+00,  6.5215e+00,  ..., -1.2482e+00,\n",
      "          -5.2519e-01,  7.6988e-01],\n",
      "         [-1.2062e+01, -3.0549e+00,  3.1566e+00,  ..., -1.6747e+00,\n",
      "          -1.9740e+00, -4.2042e-01],\n",
      "         ...,\n",
      "         [-8.0082e+00, -3.0474e+00,  3.5415e+00,  ..., -2.0588e+00,\n",
      "          -2.7357e+00, -6.6309e-01],\n",
      "         [-9.0567e+00, -2.9443e+00,  4.4974e+00,  ..., -2.2417e+00,\n",
      "          -3.0491e+00, -3.3858e-01],\n",
      "         [-7.9153e+00, -2.8651e+00,  4.2635e+00,  ..., -1.6429e+00,\n",
      "          -2.6986e+00, -6.3881e-01]],\n",
      "\n",
      "        [[ 1.8973e+01, -1.2546e+00,  9.0026e+00,  ..., -5.0097e-02,\n",
      "          -4.6533e-01,  5.5451e+00],\n",
      "         [-1.9540e+01, -1.9486e+00,  4.8008e+00,  ...,  1.2712e+00,\n",
      "           1.3955e+00, -3.5138e-01],\n",
      "         [-1.2785e+01, -2.5786e+00,  4.5447e+00,  ...,  1.4745e-02,\n",
      "          -6.4502e-02, -9.0161e-01],\n",
      "         ...,\n",
      "         [-1.0613e+01, -2.3174e+00,  6.3341e+00,  ...,  5.5351e-01,\n",
      "          -3.5263e-01,  8.9897e-01],\n",
      "         [-1.1312e+01, -2.3631e+00,  5.6110e+00,  ...,  2.8104e-01,\n",
      "          -5.0553e-01, -2.8297e-01],\n",
      "         [-1.0527e+01, -2.2015e+00,  6.5269e+00,  ...,  4.5338e-01,\n",
      "          -6.7401e-01,  6.7080e-01]],\n",
      "\n",
      "        [[ 1.6615e+01, -1.3459e+00,  6.1026e+00,  ..., -1.1386e+00,\n",
      "          -6.2780e-02,  4.6385e+00],\n",
      "         [-1.3630e+01, -2.1224e+00,  8.2479e+00,  ..., -2.4098e-01,\n",
      "          -1.1786e+00,  4.1581e+00],\n",
      "         [-1.2633e+01, -3.1703e+00,  5.3968e+00,  ..., -2.9692e+00,\n",
      "          -2.8034e+00,  5.8610e-01],\n",
      "         ...,\n",
      "         [-1.4726e+01, -3.2450e+00,  2.6638e+00,  ..., -2.2069e+00,\n",
      "          -2.1578e+00, -2.5729e-01],\n",
      "         [ 1.3652e+00, -2.6696e+00,  2.3690e+00,  ..., -2.8010e+00,\n",
      "          -2.3362e+00, -6.9818e-01],\n",
      "         [-1.9817e+01, -1.8620e+00,  1.5141e+00,  ...,  6.0081e-01,\n",
      "           4.1947e-01,  4.8440e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7632e+01, -1.1574e+00,  5.5477e+00,  ..., -1.2296e+00,\n",
      "          -1.6738e+00,  3.3676e+00],\n",
      "         [-1.7886e+01, -2.3072e+00,  5.5999e+00,  ..., -5.3172e-01,\n",
      "           1.0136e-01, -1.9271e+00],\n",
      "         [-9.2639e+00, -3.0835e+00,  3.2967e+00,  ..., -2.1041e+00,\n",
      "          -2.4094e+00, -2.5274e+00],\n",
      "         ...,\n",
      "         [-7.5496e+00, -3.0832e+00,  3.9473e+00,  ..., -2.4407e+00,\n",
      "          -2.6452e+00, -2.3578e+00],\n",
      "         [-4.4622e+00, -3.1241e+00,  4.3306e+00,  ..., -2.6859e+00,\n",
      "          -3.1759e+00, -1.5191e+00],\n",
      "         [-6.2894e+00, -2.9874e+00,  4.2215e+00,  ..., -2.2387e+00,\n",
      "          -2.8441e+00, -1.3121e+00]],\n",
      "\n",
      "        [[ 1.7165e+01, -7.0878e-01,  7.8080e+00,  ...,  2.8924e+00,\n",
      "           2.4351e+00,  6.1844e+00],\n",
      "         [-2.4532e+01, -1.7554e+00,  5.7068e+00,  ...,  4.0973e-01,\n",
      "          -2.9998e-01,  1.1336e+00],\n",
      "         [-1.5370e+01, -2.9970e+00,  2.8268e+00,  ..., -1.0792e+00,\n",
      "          -1.6461e+00, -2.5315e+00],\n",
      "         ...,\n",
      "         [-1.3482e+01, -3.0234e+00,  3.7985e+00,  ..., -2.0216e+00,\n",
      "          -2.6683e+00, -1.5635e+00],\n",
      "         [-1.3827e+01, -2.9459e+00,  6.1044e+00,  ..., -2.7568e+00,\n",
      "          -3.2997e+00, -1.6329e+00],\n",
      "         [-1.1854e+01, -2.8387e+00,  2.9870e+00,  ..., -1.5481e+00,\n",
      "          -2.0751e+00, -9.2671e-01]],\n",
      "\n",
      "        [[ 1.8487e+01, -9.1344e-01,  8.7808e+00,  ..., -5.6172e-01,\n",
      "          -4.9647e-01,  6.1239e+00],\n",
      "         [-8.6170e+00, -2.7658e+00,  2.4483e+00,  ..., -2.5233e+00,\n",
      "          -2.2836e+00, -2.4980e+00],\n",
      "         [-1.0056e+00, -1.7672e+00,  1.2726e+00,  ...,  5.9809e-01,\n",
      "           1.3009e+00,  8.3818e-01],\n",
      "         ...,\n",
      "         [-1.9095e+00, -2.3236e+00,  2.9501e+00,  ..., -1.9126e-01,\n",
      "           1.2630e-01, -1.1966e+00],\n",
      "         [-1.6674e+00, -2.3272e+00,  2.9907e+00,  ..., -2.1896e-01,\n",
      "           1.4130e-01, -1.3094e+00],\n",
      "         [-5.1204e-01, -1.9803e+00,  3.2426e+00,  ..., -9.6821e-02,\n",
      "           2.3097e-01, -2.0979e-01]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "__batch_size__ = 8\n",
    "__en_seq_length__ = random.randint(13, 23)\n",
    "__de_seq_length__ = random.randint(13, 23)\n",
    "__encoder_input__ = torch.randint(low=0, high=hi_en_bart_tokenizer.vocab_size, size=(__batch_size__, __en_seq_length__))\n",
    "__decoder_input__ = torch.randint(low=0, high=en_bart_tokenizer.vocab_size, size=(__batch_size__, __de_seq_length__))\n",
    "__encoder_input__ = __encoder_input__.to(MBART_MODEL_CONDITIONAL_GENERATION_DEVICE)\n",
    "__decoder_input__ = __decoder_input__.to(MBART_MODEL_CONDITIONAL_GENERATION_DEVICE)\n",
    "__out__ = __model__.model(input_ids=__encoder_input__, decoder_input_ids=__decoder_input__, return_dict=True)\n",
    "print(f\"Model has a total of {__model__.model.num_parameters()} number of parameters\")\n",
    "print(\"Model encoder input size: \", __encoder_input__.size())\n",
    "print(\"Model decoder input size: \", __decoder_input__.size())\n",
    "print(\"Model output type: \", type(__out__))\n",
    "print(\"Model output size: \", __out__.logits.size())\n",
    "print(\"Model output:\\n\", __out__.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c5348-beb1-40e6-a067-05611f9bcc35",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1f83ac1-b9b8-4b7d-8c70-b2a3a4c24c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tokenized dataset\n",
    "dataset = get_tokenized_dataset_models(\n",
    "    train_df=train_df,\n",
    "    validation_df=validation_df,\n",
    "    test_df=test_df,\n",
    "    encoder_tokenizer=hi_en_bart_tokenizer,\n",
    "    decoder_tokenizer=en_bart_tokenizer,\n",
    "    denoising_stage=True\n",
    ")\n",
    "train_dataset, validation_dataset, test_dataset = dataset[MBART_DATALOADER_TRANSLATION_MODE].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e44250c1-189f-4bf1-b17e-5298bee7b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Dataset\n",
      "Number of instances:  174443\n",
      "Denoising stage:  True\n",
      "Source language:  hi_en\n",
      "Target language:  hi_en\n",
      "Key: input_ids, Value: tensor([    0,  3497,    15, 10386,  1071,  2025,  2185,  6089,   278,    15,\n",
      "         1088,  4175,  2430,  2185,   392, 33673,  1711,  1963,   291,  1104,\n",
      "         1067,  1758,   278,    17,     2,     1,     1,     1,     1,     1]), Value shape: torch.Size([30])\n",
      "Key: attention_mask, Value: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0]), Value shape: torch.Size([30])\n",
      "Key: labels, Value: tensor([    0,  3497,    15, 10386,  1071,  2025,  2185,  6089,   278,    15,\n",
      "         1088,  4175,  2430,  2185,   392, 33673,  1711,  1963,   291,  1104,\n",
      "         1067,  1758,   278,    17,     2,  -100,  -100,  -100,  -100,  -100]), Value shape: torch.Size([30])\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "train_dataset.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee9471db-2a4a-47e1-85f3-15834cb97d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the model...\n",
      "\n",
      "Configuring optimizer and scheduler...\n",
      "\n",
      "Configuring collator...\n",
      "\n",
      "Configuring trainer...\n",
      "\n",
      "Configuring training arguments...\n"
     ]
    }
   ],
   "source": [
    "# Initalize the model\n",
    "mt_hg_model = CodeMixedModelHGTrainer(\n",
    "    train_dataset = train_dataset,\n",
    "    validation_dataset = validation_dataset,\n",
    "    test_dataset = test_dataset,\n",
    "    encoder_tokenizer=hi_en_bart_tokenizer,\n",
    "    decoder_tokenizer=en_bart_tokenizer,\n",
    "    denoising_stage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31529d3-0b49-40d7-9739-c9f141339bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "mt_hg_model.fit(skip_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81f306-dae2-4ef3-b0f2-1d94539c587d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate model on test data\n",
    "mt_hg_model.predict(model_path=MBART_MODEL_CONDITIONAL_GENERATION_RESUME_FROM_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01839165-c0d1-466e-801b-012043265f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "src = \"film <mask> kya <mask> hai?\"\n",
    "print(f\"\\nSRC: {src}\\nTGT: {mt_hg_model.infer(model_path=MBART_MODEL_CONDITIONAL_GENERATION_RESUME_FROM_CHECKPOINT, src=src)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
